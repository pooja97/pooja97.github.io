<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Hyperspace by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Pooja Yadav</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="generic.html" class="active">Internships</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Internship & Work Experience</h1>
							<!-- <span class="image fit"><img src="images/DigitalNil.png" alt="" /></span> -->
							<h2>International Flavors & Fragrances, Inc</h2>
							<p><h4>Scientist I</h4></p>
							<p>neered data solutions to optimize high-throughput screening workflows in chemistry R&D, improving efficiency by 20% and ensuring accurate, structured data collection for chemical experiments
								Developed scalable database architectures to process 1M+ experimental data points from diverse chemical experiments, ensuring efficient data storage, retrieval, and integrity enhancing data accessibility for cross-functional teams
								Automated 80% of data pipelines, reducing manual intervention and accelerating data processing by 30%
								Built and deployed web applications for real-time data analysis, improving data reporting efficiency for R&D by 40%
							</p>
							<h2>Getinge</h2>
							<p><h4>Data Engineer </h4></p>
							<p>Azure Data Engineer at Getinge a medical device manufacturing company.
								Orchestrating an end-to-end data ingestion and transformation using Rest APIs, Azure Databricks with Medallion architecture, and ADLS Gen 2, optimizing workflows for efficient creation of vector embeddings fed into a chatbot system leveraging LLMs.
								Designed asynchronous API request calls with a rate-limiting mechanism using a Token bucket algorithm. 
								Building and maintaining robust data pipelines in Azure Synapse, ensuring seamless data ingestion from diverse on-prem source systems into Data Lake and PostgreSQL ensuring data quality standards.Orchestrating an end-to-end data ingestion and transformation using Rest APIs, Azure Databricks with Medallion architecture, and ADLS Gen 2, optimizing workflows for efficient creation of vector embeddings fed into a chatbot system leveraging LLMs. Designed asynchronous API request calls with a rate-limiting mechanism using a Token bucket algorithm. 
							</p>

							<h2>MVP Lab SDSU</h2>
							<p><h4>Research Associate: Machine Learning Engineer</h4></p>
							<p>Enhanced an AI-based real estate service at Computer Vision Lab SDSU to rate 1.2 million housing communities in San Diego.
								Automated and accelerated the collection of Google Street View data by 40% using Selenium, Python, and OpenCV for efficient preprocessing.
								Trained a YOLOv8 model on custom data to detect roadways, utilized Segment Anything Model by Meta to segment YOLOv8 modelâ€™s detection reducing the segmentation time by 55%.
								Applied pre-trained VGG16 for feature extraction, Principal Component Analysis for dimensionality reduction, and KMeans clustering to cluster and rate image data into ten distinct groups based on the extracted features. Performed 3D cluster analysis using Seaborn and Plotly.js
								Analyzed Elbow graph to find the optimal value for K and calculated Silhouette score for each cluster to find the quality of the cluster.</p>

							<h2>San Diego State University</h2>
							<p><h4>Teaching Assistant</h4></p>
							<p>Teaching Assistant for the course Wireless Networks (CS-578)</p>

							<h2>LifeBand LLC</h2>
							<p><h4>Software Engineer Intern</h4></p>
							<p>Orchestrated a 40% reduction in daily data processing time by efficient data ingestion through Airflow DAGs for a robust 3NF-compliant database schema, ensuring data integrity in collaboration with the cross-functional teams.
								Designed and Developed REST APIs using the Django-Rest framework and PostgreSQL database, ensuring seamless and robust data interaction for optimal system performance
								Spearheaded the implementation of streamlined software development processes with BitBucket CI/CD, resulting in a 50% reduction in deployment time
								</p>
							
							<h2>AI4Business Lab SDSU</h2>
							<p><h4>Research Assistant</h4></p>
							<p> Extracted Covid-19 Twitter data using tweepy to predcit the Covid-19 vaccine company's stock prices based on the Twitter user's sentiments. 
								Summarized Covid-19 articles, research papers, and events that affected the Vaccine companies' stock prices. 
								Analyzed and Visualized Covid-19 vaccine companies' stock prices and people's sentiments using Pandas, NumPy and Seaborn. 
								Performed stock price forecasting using LSTM.</p>
								
							<h2>San Diego State University Research Foundation</h2>
							<p><h4>Data Analyst Intern</h4></p>
							<p> Developed a web application using Streamlit, Python, Pandas, and NumPy to analyse and monitor 67 million rows of rain and temperature Time Series geospatial data.
								Implemented parallel processing using Swifter and Pandarallel to speed up the data manipulation and cleaning process by 80% Extracted location using geoPy module and visualized geospatial data using Plotly, Altair Charts, and Folium.
								Created bi-directional communication on a folium map using haversine distance to cut down the nearest latitude-longitude search time by 20%, deployed the application with docker container on AWS. 
								</p>
							<h2>Infosys LTD</h2>
							<p><h4>Data Engineer</h4></p>
							<p> Achieved 75% improvement in data transfer efficiency by orchestrating and implementing a high-throughput data ingestion pipeline using Kafka streaming, enhancing the data storage speed in Snowflake
								Developed Python scripts to optimize data retrieval from REST APIs, increasing the pipeline's data source efficiency
								Implemented Airflow for job scheduling, achieving 30% manual work reduction and automated, timely data processing
								<br>
								</p>

						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>